{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bittensorflowconda54ed7f0b4ae145b3b6255fb760996329",
   "display_name": "Python 3.8.2 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n(442, 10)\n(442,)\n0.0380759064334241\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Diabetes dataset for regression or classification: \n",
    "# The goal of the script is to first classify if a patient \n",
    "# has diabetes or not based on multiple features like:\n",
    "#   Patient age\n",
    "#   Patient sex\n",
    "#   Patient BMI\n",
    "#   Patient average blood pressure\n",
    "#   Six blood serum measurements\n",
    "# All of these features are measured on 442 patients, and used\n",
    "# as an indicator of disease progression after one year.\n",
    "\n",
    "# First we load the dataset\n",
    "# Here we see that the \"x\" value represents each person and their\n",
    "# 10 features. While the \"y\" values represents each person.\n",
    "# The diabetes dataset is returned as a \"regression\" dataset\n",
    "data = load_diabetes()\n",
    "x, y = data['data'], data['target']\n",
    "print(data[\"feature_names\"])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x[0][0])"
   ]
  },
  {
   "source": [
    "# Since the diabetes dataset is loaded as a regression dataset,\n",
    "# we have to convert it to a classification problem.\n",
    "\n",
    "# First we create an array of zeros with the same size as \"y\"\n",
    "# Then we set each element to 1 in our \"y_\" array, where in the \"y\" array\n",
    "# the correspoding element is bigger than 140. Then we convert the values\n",
    "# of decimals in \"y_\" to integers.\n",
    "y_ = np.zeros(y.shape)\n",
    "y_[y > 140] = 1.\n",
    "y_ = y_.astype(int)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: (353, 10) (353,)\nTest dataset (89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "# Then we split our data into 80% training data and 20% testing data\n",
    "# The \"random_state\" parameter is used for reprodruction of the data. \n",
    "# The stratify parameter makes sure that \"y_\" is equally represented \n",
    "# in both training and test. This type of setup is called holdout.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_, test_size=0.2, random_state=42, stratify=y_)\n",
    "print(\"Train dataset:\", x_train.shape, y_train.shape)\n",
    "print(\"Test dataset\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.66666667 1.         0.42180095 ... 0.42313117 0.54263407 0.72727273]\n [0.56666667 0.         0.28909953 ... 0.28208745 0.54549947 0.56060606]\n [0.05       0.         0.23696682 ... 0.14104372 0.20026662 0.5       ]\n ...\n [0.71666667 1.         0.65402844 ... 0.42313117 0.5702869  0.60606061]\n [0.25       1.         0.12322275 ... 0.         0.15120886 0.51515152]\n [0.23333333 1.         0.3507109  ... 0.42313117 0.56492788 0.71212121]]\n"
     ]
    }
   ],
   "source": [
    "# Standardise the data so that all the data has a range between 0 and 1, \n",
    "# instead of between -1 and 1.\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_train_ = min_max_scaler.fit_transform(x_train)\n",
    "x_test_ = min_max_scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}